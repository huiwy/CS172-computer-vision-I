{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import utils\n",
    "import BoW\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0\n",
    "patch_size = 0\n",
    "dim = 1024\n",
    "num_kmeans_samples = 20000\n",
    "train_number = 15\n",
    "caltech_repo = \"./256_ObjectCategories/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the codebook and initialize the feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the phase of getting bag of words, we don't need to and also cannot load all the images.\n",
    "bag_of_words_dataset = utils.Dataset_old(caltech_repo, drop_rate = 0.9)\n",
    "# get the dictionary of the Bag of Words.\n",
    "kmeans_model = BoW.generate_kmeans_model(bag_of_words_dataset.get_data_X(), \n",
    "                   dim, patch_size, step_size, num_kmeans_samples)\n",
    "# get the feature function\n",
    "feature_func = lambda x: BoW.feature_function_model_unfeeded(\n",
    "                                x, dim, step_size, patch_size, kmeans_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the full dataset in feature representation.\n",
    "BoW_dataset = utils.Dataset(caltech_repo, \n",
    "                   feature_function = feature_func)\n",
    "BoW_dataset.generate_train_test_samples()\n",
    "\n",
    "SPM_dataset = utils.Dataset(caltech_repo, pyramid = 2,\n",
    "                   feature_function = feature_func)\n",
    "SPM_dataset.generate_train_test_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "gamma = 1/dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "RBF_SVC = SVC(kernel='rbf', C=C, gamma = gamma)\n",
    "Linear_SVC = SVC(kernel='linear', C=C)\n",
    "HIV_SVC = utils.HistIntersectionModel(C=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = # BoW_dataset or SPM_dataset\n",
    "model = # RBF_SVC or Linear_SVC or HIV_SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on the dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = data_set.train(scaler, model, training_number)\n",
    "validation_acc = data_set.test(scaler, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = data_set.train(scaler, model, validation = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {}\n",
    "\n",
    "Cs = np.pow(np.random.uniform(-1, 1, 10), 10)\n",
    "gammas = np.pow(np.random.uniform(-5, -3, 10), 10)\n",
    "\n",
    "for C, gamma in zip(Cs, gammas):\n",
    "    RBF_SVC = SVC(kernel='rbf', C=C, gamma = gamma)\n",
    "    training_acc = data_set.train(scaler, model, training_number)\n",
    "    validation_acc = data_set.test(scaler, model)\n",
    "    \n",
    "    record[(C, gamma)] = (training_acc, validation_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda3e879a01d331491c87eff9c666fa0563"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
